{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92603af-2534-42a2-bfec-f40568080bae",
   "metadata": {},
   "source": [
    "# PHY480 Day 2\n",
    "\n",
    "## In-class activity: Experiments with round-off errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b36ed-1f9b-4b3d-808f-0e3fa8c9194c",
   "metadata": {},
   "source": [
    "Floating-precision representation of real numbers on a computer allows one to store about 7 significant digits in single precision (4 bytes or 32 bits) and about 15 digits in double precision (8 bytes or 64 bits). Python by default represents numbers and performs arithmetic in double precision. However, there may be situations where you need to use a single-precision representation. We would like to explore both. Luckily, the NumPy package allows one to control precision with two functions: `float32` and `float64`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5640436-35ef-4f95-815d-7b136a236b96",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "\n",
    "To understand the effect of the round-off error we perform the following experiment. Let us calculate the following sum:\n",
    "\n",
    "$$\n",
    "f(n)=\\sum_{k=0}^n k^2\n",
    "$$\n",
    "\n",
    "as function of $n$. We can do this in two ways: a) summing from $k=0$ to $k=n$ (forward), or b) summing from $k=n$ to $k=0$ (backward). The difference of the two should be 0, as the result should not depend on the order of summation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95e2cd5-5f3a-4a49-a291-b49453380197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function that computes the sum of squares of integers up to n\n",
    "# Input:\n",
    "# n -- the number of terms\n",
    "# reverse_order -- if True, sum in the reverse order\n",
    "# double_prec -- if True, use double precision float64, otherwise single precision float32\n",
    "# Output:\n",
    "# the sum\n",
    "def compute_k2_sum( n, reverse_order=False, double_prec=False ):\n",
    "\n",
    "    # control the order of summation\n",
    "    if reverse_order:\n",
    "        R = range(n,-1,-1)\n",
    "    else:\n",
    "        R = range(0,n+1)\n",
    "\n",
    "    # control single/double precision\n",
    "    if double_prec:\n",
    "        fp_prec = np.float64\n",
    "    else:\n",
    "        fp_prec = np.float32\n",
    "\n",
    "    s = fp_prec( 0 ) # it is important to initialize the sum in precision we need\n",
    "    for k in R:\n",
    "        x = fp_prec( k ) # convert integer k into x of the precision we need\n",
    "        s += x*x\n",
    "\n",
    "    return s\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee0a0d85-0e44-4228-ac40-db95cae9e6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14133840000000000000e+07\n",
      "2.14132800000000000000e+07\n",
      "1.04000000000000000000e+02\n"
     ]
    }
   ],
   "source": [
    "N = 400 # experiment with increasing N until you see the effect of the round-off errors\n",
    "\n",
    "# compute the sums: experiment with double_prec=False and double_prec=True\n",
    "s1 = compute_k2_sum( N, reverse_order=False, double_prec=False )\n",
    "s2 = compute_k2_sum( N, reverse_order=True, double_prec=False )\n",
    "\n",
    "# print out the sums individually and their difference\n",
    "print( \"{:.20e}\".format( s1 ) )\n",
    "print( \"{:.20e}\".format( s2 ) )\n",
    "print( \"{:.20e}\".format( s1 - s2 ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5118e58d-0fca-4887-b4ca-39fabb36ad10",
   "metadata": {},
   "source": [
    "## Experiment 2\n",
    "\n",
    "Because of the limited precision of floating point numbers, there is a notion of _machine epsilon_ $\\varepsilon_m$, i.e. the smallest number that can be represented on computer that the following is true:\n",
    "\n",
    "$$\n",
    "1+\\varepsilon_m > 1.\n",
    "$$\n",
    "\n",
    "We can employ a simple iterative algorithm for estimating $\\varepsilon_m$: start with $\\varepsilon_m=1$ and keep dividing by 2 until we reach $1+\\varepsilon_m=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08b9fef7-9327-467b-b5de-ba745296ceb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 24\n",
      "Machine epsilon: 1.1920929e-07\n"
     ]
    }
   ],
   "source": [
    "fp_prec = np.float32 # experiment with np.float32 (single) and np.float64 (double)\n",
    "\n",
    "one = fp_prec( 1 )\n",
    "epsilon = one\n",
    "\n",
    "max_iter = 100 # it is a good idea to set the maximum number of iterations to avoid accidental infinite loops\n",
    "i = 0\n",
    "while one + epsilon > one and i < max_iter:\n",
    "    epsilon /= fp_prec( 2 )\n",
    "    i += 1\n",
    "\n",
    "epsilon *= fp_prec( 2 ) # the last iteration is when the inequality is not satisfied,\n",
    "                        # so the actual value is the one next to last\n",
    "\n",
    "print( \"Iterations:\", i )\n",
    "print( \"Machine epsilon:\", epsilon )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cdb178-12cd-469b-aaa7-6c5baed60851",
   "metadata": {},
   "source": [
    "We can compare our estimate with the built-in values of machine epsilon that NumPy uses internally. Search up on how to print out the NumPy machine epsilon values and print them in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05aa5075-119d-437c-9737-4d1e43adab74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine parameters for float32\n",
      "---------------------------------------------------------------\n",
      "precision =   6   resolution = 1.0000000e-06\n",
      "machep =    -23   eps =        1.1920929e-07\n",
      "negep =     -24   epsneg =     5.9604645e-08\n",
      "minexp =   -126   tiny =       1.1754944e-38\n",
      "maxexp =    128   max =        3.4028235e+38\n",
      "nexp =        8   min =        -max\n",
      "smallest_normal = 1.1754944e-38   smallest_subnormal = 1.4012985e-45\n",
      "---------------------------------------------------------------\n",
      " Machine parameters for float64\n",
      "---------------------------------------------------------------\n",
      "precision =  15   resolution = 1.0000000000000001e-15\n",
      "machep =    -52   eps =        2.2204460492503131e-16\n",
      "negep =     -53   epsneg =     1.1102230246251565e-16\n",
      "minexp =  -1022   tiny =       2.2250738585072014e-308\n",
      "maxexp =   1024   max =        1.7976931348623157e+308\n",
      "nexp =       11   min =        -max\n",
      "smallest_normal = 2.2250738585072014e-308   smallest_subnormal = 4.9406564584124654e-324\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE\n",
    "\n",
    "print(np.finfo(np.float32), np.finfo(np.float64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ed4da-2be7-44bc-9950-8131ebcbd899",
   "metadata": {},
   "source": [
    "&#169; Copyright 2025,  Michigan State University Board of Trustees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d3f5cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15125"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7500+6500+625+500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
